{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOwRggVcwtzP"
      },
      "outputs": [],
      "source": [
        "from transformer import Transformer # this is the transformer.py file\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TApzOj5xCwR"
      },
      "outputs": [],
      "source": [
        "english_file = 'drive/MyDrive/translation_en_kn/train.en' # replace this path with appropriate one\n",
        "kannada_file = 'drive/MyDrive/translation_en_kn/train.kn' # replace this path with appropriate one\n",
        "\n",
        "# Generated this by filtering Appendix code\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PADDING>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
        "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
        "                      'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', \n",
        "                      'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ೠ', 'ಌ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', \n",
        "                      'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', \n",
        "                      'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', \n",
        "                      'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', \n",
        "                      'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', \n",
        "                      'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', \n",
        "                      'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', \n",
        "                      '಼', 'ಽ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ', 'ೖ', 'ೞ', 'ೣ', 'ಂ', 'ಃ', \n",
        "                      '೦', '೧', '೨', '೩', '೪', '೫', '೬', '೭', '೮', '೯', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        '[', '\\\\', ']', '^', '_', '`', \n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
        "                        'y', 'z', \n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA8ESmCrNoc7"
      },
      "outputs": [],
      "source": [
        "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
        "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SYGjRdoxRg-"
      },
      "outputs": [],
      "source": [
        "with open(english_file, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(kannada_file, 'r') as file:\n",
        "    kannada_sentences = file.readlines()\n",
        "\n",
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 200000\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUB-BkgFxXfM",
        "outputId": "bcf7e19c-d1df-4b69-bdfa-eb74ac1a4338"
      },
      "outputs": [],
      "source": [
        "english_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OT-aznAxc5U",
        "outputId": "716c4145-fdc2-4bb0-e883-c3dcad30c2da"
      },
      "outputs": [],
      "source": [
        "kannada_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8VAutsTxlaR",
        "outputId": "ff8fba72-020d-4f0c-b3c5-31c102b6fe9b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG9ezqvaxl4b",
        "outputId": "d13be774-ca07-4333-856e-76186f71caae"
      },
      "outputs": [],
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(kannada_sentences)):\n",
        "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o80QDn4CxsV7"
      },
      "outputs": [],
      "source": [
        "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xhLztQiLIQ",
        "outputId": "aa70ad04-2e45-4c78-c852-61e92c51a96a"
      },
      "outputs": [],
      "source": [
        "kannada_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqOFnclmyxAE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "d_model = 512\n",
        "batch_size = 30\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 200\n",
        "kn_vocab_size = len(kannada_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model, \n",
        "                          ffn_hidden,\n",
        "                          num_heads, \n",
        "                          drop_prob, \n",
        "                          num_layers, \n",
        "                          max_sequence_length,\n",
        "                          kn_vocab_size,\n",
        "                          english_to_index,\n",
        "                          kannada_to_index,\n",
        "                          START_TOKEN, \n",
        "                          END_TOKEN, \n",
        "                          PADDING_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc2hYQk9yxX0",
        "outputId": "c060f588-6a2e-4179-9475-5acafd641f1f"
      },
      "outputs": [],
      "source": [
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asUJX-STy7fg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, kannada_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.kannada_sentences = kannada_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.kannada_sentences[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-auNWjkdzDge"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentences, kannada_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roH2A4m4zF4z",
        "outputId": "f4353aa8-2f37-43b6-be0f-12aab9a35145"
      },
      "outputs": [],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGeHNlzozIGF",
        "outputId": "ec3596fe-feee-426c-dce8-373fb07080fd"
      },
      "outputs": [],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YDttjQ0zMrv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EnjHKB1zM8Y",
        "outputId": "1a825e56-6706-46ee-85b5-ed7f0ac657fb"
      },
      "outputs": [],
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnanjzqtzQi8"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=kannada_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_saWU5QmVem2"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdgtTSKvwN9_"
      },
      "source": [
        "Modify mask such that the padding tokens cannot look ahead.\n",
        "In Encoder, tokens before it should be -1e9 while tokens after it should be -inf.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLcXI4wkMLck"
      },
      "source": [
        "Note the target mask starts with 2 rows of non masked items: https://github.com/SamLynnEvans/Transformer/blob/master/Beam.py#L55\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju59VDGLuOqf",
        "outputId": "0ad34e31-521a-4ca2-f444-26b5374946f6"
      },
      "outputs": [],
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, kn_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
        "        optim.zero_grad()\n",
        "        kn_predictions = transformer(eng_batch,\n",
        "                                     kn_batch,\n",
        "                                     encoder_self_attention_mask.to(device), \n",
        "                                     decoder_self_attention_mask.to(device), \n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == kannada_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"Kannada Translation: {kn_batch[0]}\")\n",
        "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in kn_sentence_predicted:\n",
        "              if idx == kannada_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_kannada[idx.item()]\n",
        "            print(f\"Kannada Prediction: {predicted_sentence}\")\n",
        "\n",
        "\n",
        "            transformer.eval()\n",
        "            kn_sentence = (\"\",)\n",
        "            eng_sentence = (\"should we go to the mall?\",)\n",
        "            for word_counter in range(max_sequence_length):\n",
        "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "                predictions = transformer(eng_sentence,\n",
        "                                          kn_sentence,\n",
        "                                          encoder_self_attention_mask.to(device), \n",
        "                                          decoder_self_attention_mask.to(device), \n",
        "                                          decoder_cross_attention_mask.to(device),\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
        "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "                next_token = index_to_kannada[next_token_index]\n",
        "                kn_sentence = (kn_sentence[0] + next_token, )\n",
        "                if next_token == END_TOKEN:\n",
        "                  break\n",
        "            \n",
        "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
        "            print(\"-------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nosVPGVijId"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOQe-juylBiJ"
      },
      "outputs": [],
      "source": [
        "transformer.eval()\n",
        "def translate(eng_sentence):\n",
        "  eng_sentence = (eng_sentence,)\n",
        "  kn_sentence = (\"\",)\n",
        "  for word_counter in range(max_sequence_length):\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
        "    predictions = transformer(eng_sentence,\n",
        "                              kn_sentence,\n",
        "                              encoder_self_attention_mask.to(device), \n",
        "                              decoder_self_attention_mask.to(device), \n",
        "                              decoder_cross_attention_mask.to(device),\n",
        "                              enc_start_token=False,\n",
        "                              enc_end_token=False,\n",
        "                              dec_start_token=True,\n",
        "                              dec_end_token=False)\n",
        "    next_token_prob_distribution = predictions[0][word_counter]\n",
        "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "    next_token = index_to_kannada[next_token_index]\n",
        "    kn_sentence = (kn_sentence[0] + next_token, )\n",
        "    if next_token == END_TOKEN:\n",
        "      break\n",
        "  return kn_sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDVH_YsxlK6q",
        "outputId": "83c47f99-53c0-4c2d-c26a-aaa426f50563"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"what should we do when the day starts?\")\n",
        "print(translation)\n",
        "#ದಿನ ಪ್ರಾರಂಭವಾದಾಗ ನಾವು ಏನು ಮಾಡಬೇಕು?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9yfawBnul0W",
        "outputId": "d9e6e6b7-683b-45f9-f013-c53c31038306"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"how is this the truth?\")\n",
        "print(translation)\n",
        "#ಇದು ಹೇಗೆ ಸತ್ಯ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpdYBk5-urcQ",
        "outputId": "ca7249c5-efda-4f41-f052-ecef9691be82"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"the world is a large place with different people\")\n",
        "print(translation)\n",
        "#ಪ್ರಪಂಚವು ವಿಭಿನ್ನ ಜನರೊಂದಿಗೆ ದೊಡ್ಡ ಸ್ಥಳವಾಗಿದೆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni9e2UYUuxi3",
        "outputId": "b93968e6-3f12-4794-b277-3a3821af221e"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"my name is ajay\")\n",
        "print(translation)\n",
        "#ನನ್ನ ಹೆಸರು ಅಜಯ್"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJuJKHqFldW3",
        "outputId": "71aa2c6c-ec77-4b02-d39b-bd724012fb53"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"i cannot stand this smell\")\n",
        "print(translation)\n",
        "#ನಾನು ಈ ವಾಸನೆಯನ್ನು ಸಹಿಸುವುದಿಲ್ಲ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxHC4Lirlfu8",
        "outputId": "5a3ca401-abac-41af-d9db-99fb7a57fe00"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"noodles are the best\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLVOSI0Oli16",
        "outputId": "9f9445a1-2802-4688-900c-d7ecf2bd5c35"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"why care about this?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStWCoAt0Ixp"
      },
      "source": [
        "This translated pretty well : \"What is the reason. Why\" without punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB6TEJfGlkRT",
        "outputId": "adb465d5-b0ed-4be4-9251-62c079f49491"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"this is the best thing ever\")\n",
        "print(translation)\n",
        "# ಇದು ಎಂದೆಂದಿಗೂ ಉತ್ತಮವಾಗಿದೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxsUjSybxYkh"
      },
      "source": [
        "The translation : \"This is very unusual\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQwDbuWBlmmA",
        "outputId": "7ae0e2c0-02c0-4c74-bc47-26b67da55a06"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"i am here\")\n",
        "print(translation)\n",
        "# ನಾನು ಇಲ್ಲಿದ್ದೇನೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmyZ2-I6x0Yf"
      },
      "source": [
        "Translation: \"I have heard\". \n",
        "This is why word based translator may perform better than character translator. This is actually very good at optimizing the objective of the current transformer even though the translation is off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ifeV4bGluIj",
        "outputId": "6bce922d-d0db-432c-e6c6-97d482f1dea6"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"click this\")\n",
        "print(translation)\n",
        "# ಇದನ್ನು ಕ್ಲಿಕ್ ಮಾಡಿ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RB5DUBEl1kD",
        "outputId": "9109e504-8b9e-45dc-e13c-e878b3741e4e"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"where is the mall?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdeJ9CvMn5LM",
        "outputId": "044b5dac-29a9-4b60-e66a-4e10739a9756"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"what should we do?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoikFnov1rj-"
      },
      "source": [
        "This is correct; but it absolutely fumbles on the next one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GFeyzrg1fIZ",
        "outputId": "2b4dfb04-def2-4725-9e76-5476bf85e2ef"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"today, what should we do\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0upygLS-sXcO",
        "outputId": "53a62435-ab16-4d4c-8a9f-0bf07af2a501"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"why did they activate?\")\n",
        "print(translation)\n",
        "# ಅವರು ಏಕೆ ಸಕ್ರಿಯಗೊಳಿಸಿದರು?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSrsqEGmtcl2",
        "outputId": "1b8b8faa-5370-426a-f2f2-fe852696bf7a"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"why did they do this?\")\n",
        "print(translation)\n",
        "# ಅವರು ಇದನ್ನು ಏಕೆ ಮಾಡಿದರು?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ISM5rd3BLJ"
      },
      "source": [
        "That turned out well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTcH2HFtyld",
        "outputId": "9dea5498-f139-4cbd-ee8c-6108e1b92fc4"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"i am well.\")\n",
        "print(translation)\n",
        "# ನಾನು ಆರಾಮವಾಗಿದ್ದೇನೆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP0YX2g74eP7"
      },
      "source": [
        "Translation: \"I will give you something\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pGdN13kt5Br",
        "outputId": "240256c5-f594-41b0-8218-2c70a22a156f"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"whats the word on the street?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFYZ6pOe4o-X"
      },
      "source": [
        "Kind of close semantically. Translation is something like: \"What is this about\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrOcNUk1-e5"
      },
      "source": [
        "## Insights\n",
        "\n",
        "- When training, we can treat every alphabet as a single unit instead of splitting it into it's corresponding parts to preserve meaning. For example, ಮಾ should be 1 unit when comuting a loss. It should not be decomposed into ಮ + ఆ\n",
        "- Using word-based or BPE based tokenizations may help mitigate (1). Also, we will get valid word (or BPE) units if we do so. \n",
        "- Make sure the training set has a large variety of sentences that are not just about one topic like \"work\" and \"government\"\n",
        "- Increase the number of encoder / decoder units for better translations. It was set to the minimum of 1 of each unit here.\n",
        "- Create a translator with a language you understand ideally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd6_k0Uu5V7f"
      },
      "source": [
        "Overall, this model definately learned something. And you can use other languages instead of this kannada language and might see better luck"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
